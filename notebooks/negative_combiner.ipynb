{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dictionaries that store relationship between articles and categories in different languages\n",
    "\n",
    "temp_directory = \"../data/\"\n",
    "\n",
    "with open(os.path.join(temp_directory, 'language_title_dict.pkl'), 'rb') as f:\n",
    "    language_title_dict = pickle.load(f)\n",
    "with open(os.path.join(temp_directory, 'language_category_article_mapping'), 'rb') as f:\n",
    "    language_category_article_mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"C:\\Users\\onurg\\.cache\\huggingface\\datasets\"\n",
    "data_dir = \"updated_wiki40b\"\n",
    "\n",
    "# Long dataset to process to have the final version\n",
    "path = os.path.join(root_dir, data_dir, \"long_small_en\")\n",
    "dataset = load_from_disk(path)\n",
    "print(len(dataset))\n",
    "\n",
    "# Wide dataset for finding hard negatives\n",
    "path = os.path.join(root_dir, data_dir, \"filtered_small\")\n",
    "dataset_wide = load_from_disk(path)\n",
    "print(len(dataset_wide))\n",
    "df = dataset_wide.to_pandas()\n",
    "df.set_index('wikidata_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Negative Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some results:\n",
    "\n",
    "\"Q3588472\": Émile Dubonnet, French balloonist  <br />\n",
    "\"Q588510\": Jacques Balsan, French aviator and businessman\n",
    "\n",
    "\"Q206961\": Épinay-sur-Seine, commune in Seine-Saint-Denis <br />\n",
    "\"Q175999\": Le Pré-Saint-Gervais, commune in Seine-Saint-Denis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_negative_finder(language: str, initial_article:str, language_title_dict: dict, language_category_article_mapping: dict) -> str:\n",
    "    cat_list = language_title_dict[language][initial_article]\n",
    "    category = random.choice(cat_list)\n",
    "    available_articles = [article for article in language_category_article_mapping[language][category] if article != initial_article]\n",
    "    selected_article = random.choice(available_articles)\n",
    "    return selected_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "language = \"en\"\n",
    "initial_article = \"Q206961\"\n",
    "\n",
    "selected_article = hard_negative_finder(language, initial_article, language_title_dict, language_category_article_mapping)\n",
    "print(selected_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In order to create reverse pair for each available pair\n",
    "# def create_reverse_pair(example):\n",
    "\n",
    "#     second_pairs = []\n",
    "#     for pair in example[\"pair\"]:\n",
    "#         first_lan, second_lan = pair.split(\"_\")\n",
    "#         second_pairs.append(f\"{second_lan}_{first_lan}\")\n",
    "     \n",
    "#     example = {\"pair\": example[\"pair\"] + second_pairs,\n",
    "#                \"article_1\": example[\"article_1\"] + example[\"article_2\"],\n",
    "#                \"article_2\": example[\"article_2\"] + example[\"article_1\"],\n",
    "#                \"wikidata_id\": example[\"wikidata_id\"] + example[\"wikidata_id\"]}\n",
    "#     return example\n",
    "\n",
    "\n",
    "# long_dataset = dataset.map(create_reverse_pair, \n",
    "#                                 batched=True, \n",
    "#                                 batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining with Reverse Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def negative_combiner_wrapper(dataset: datasets.Dataset, language_title_dict: dict, language_category_article_mapping: dict, df:pd.DataFrame) -> datasets.Dataset:\n",
    "#     def negative_combiner(example):\n",
    "#         anchor_language = example[\"pair\"].split(\"_\")[0]\n",
    "#         wiki_id = example[\"wikidata_id\"]\n",
    "\n",
    "#         if wiki_id in language_title_dict[anchor_language]:\n",
    "#             selected_article = hard_negative_finder(anchor_language,wiki_id,language_title_dict, language_category_article_mapping)                 \n",
    "#             example[\"hard_negative\"] = df.loc[selected_article][f\"text_{anchor_language}\"]\n",
    "#         else:\n",
    "#             example[\"hard_negative\"] = None\n",
    "\n",
    "#         return example  \n",
    "\n",
    "#     final_dataset = dataset.map(negative_combiner, num_proc=8)\n",
    "#     return final_dataset\n",
    "\n",
    "# final_dataset = negative_combiner_wrapper(long_dataset, language_title_dict, language_category_article_mapping, df)\n",
    "# print(len(final_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dataset = final_dataset.filter(lambda example: example[\"hard_negative\"], num_proc=8)\n",
    "# print(len(final_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_combiner_wrapper(dataset: datasets.Dataset, language_title_dict: dict, language_category_article_mapping: dict, df:pd.DataFrame) -> datasets.Dataset:\n",
    "    def negative_combiner(example):\n",
    "        anchor_languages = example[\"pair\"].split(\"_\")\n",
    "        wiki_id = example[\"wikidata_id\"]\n",
    "\n",
    "        example[\"article_3\"] = example[\"article_4\"] = None\n",
    "\n",
    "        for language, idx in zip(anchor_languages, range(3,5)):\n",
    "            if wiki_id in language_title_dict[language]:\n",
    "                selected_article = hard_negative_finder(language, wiki_id, language_title_dict, language_category_article_mapping)                 \n",
    "                example[f\"article_{idx}\"] = df.loc[selected_article][f\"text_{language}\"]\n",
    "\n",
    "        return example  \n",
    "\n",
    "    final_dataset = dataset.map(negative_combiner, num_proc=8)\n",
    "    return final_dataset\n",
    "\n",
    "final_dataset = negative_combiner_wrapper(dataset, language_title_dict, language_category_article_mapping, df)\n",
    "print(len(final_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = final_dataset.filter(lambda example: example[\"article_3\"] and example[\"article_4\"], num_proc=8)\n",
    "print(len(final_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(root_dir, data_dir, \"final_small_en\")\n",
    "final_dataset.save_to_disk(path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33ab4daa0c7d977fc22aa25c36b9c12b9e43d0049f266348c79f509c14309a26"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
