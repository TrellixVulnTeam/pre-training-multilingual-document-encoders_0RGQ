{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import datasets\n",
    "\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dictionaries that store relationship between articles and categories in different languages\n",
    "\n",
    "temp_directory = \"../data/\"\n",
    "\n",
    "with open(os.path.join(temp_directory, 'language_title_dict.pkl'), 'rb') as f:\n",
    "    language_title_dict = pickle.load(f)\n",
    "with open(os.path.join(temp_directory, 'language_category_article_mapping'), 'rb') as f:\n",
    "    language_category_article_mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"C:\\Users\\onurg\\.cache\\huggingface\\datasets\"\n",
    "data_dir = \"updated_wiki40b\"\n",
    "\n",
    "# Long dataset to process to have the final version\n",
    "path = os.path.join(root_dir, data_dir, \"long_small_en\")\n",
    "dataset = load_from_disk(path)\n",
    "print(len(dataset))\n",
    "\n",
    "# Wide dataset for finding hard negatives\n",
    "path = os.path.join(root_dir, data_dir, \"filtered_small\")\n",
    "dataset_wide = load_from_disk(path)\n",
    "print(len(dataset_wide))\n",
    "df = dataset_wide.to_pandas()\n",
    "df.set_index('wikidata_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Negative Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some results:\n",
    "\n",
    "\"Q3588472\": Émile Dubonnet, French balloonist  <br />\n",
    "\"Q588510\": Jacques Balsan, French aviator and businessman\n",
    "\n",
    "\"Q206961\": Épinay-sur-Seine, commune in Seine-Saint-Denis <br />\n",
    "\"Q175999\": Le Pré-Saint-Gervais, commune in Seine-Saint-Denis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_negative_finder(language: str, initial_article:str, language_title_dict: dict, language_category_article_mapping: dict) -> str:\n",
    "    cat_list = language_title_dict[language][initial_article]\n",
    "    category = random.choice(cat_list)\n",
    "    available_articles = [article for article in language_category_article_mapping[language][category] if article != initial_article]\n",
    "    selected_article = random.choice(available_articles)\n",
    "    return selected_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "language = \"en\"\n",
    "initial_article = \"Q206961\"\n",
    "\n",
    "selected_article = hard_negative_finder(language, initial_article, language_title_dict, language_category_article_mapping)\n",
    "print(selected_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to create reverse pair for each available pair\n",
    "def create_reverse_pair(example):\n",
    "\n",
    "    second_pairs = []\n",
    "    for pair in example[\"pair\"]:\n",
    "        first_lan, second_lan = pair.split(\"_\")\n",
    "        second_pairs.append(f\"{second_lan}_{first_lan}\")\n",
    "     \n",
    "    example = {\"pair\": example[\"pair\"] + second_pairs,\n",
    "               \"article_1\": example[\"article_1\"] + example[\"article_2\"],\n",
    "               \"article_2\": example[\"article_2\"] + example[\"article_1\"],\n",
    "               \"wikidata_id\": example[\"wikidata_id\"] + example[\"wikidata_id\"]}\n",
    "    return example\n",
    "\n",
    "\n",
    "long_dataset = dataset.map(create_reverse_pair, \n",
    "                                #remove_columns=long_dummy_dataset.column_names, \n",
    "                                batched=True, \n",
    "                                batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_combiner_wrapper(dataset: datasets.Dataset, language_title_dict: dict, language_category_article_mapping: dict, df:pd.DataFrame) -> datasets.Dataset:\n",
    "    def negative_combiner(example):\n",
    "        anchor_language = example[\"pair\"].split(\"_\")[0]\n",
    "        wiki_id = example[\"wikidata_id\"]\n",
    "        if wiki_id in language_title_dict[anchor_language]:\n",
    "            selected_article = hard_negative_finder(anchor_language, wiki_id, language_title_dict, language_category_article_mapping)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        example[\"hard_negative\"] = df.loc[selected_article][f\"text_{anchor_language}\"]\n",
    "\n",
    "        return example\n",
    "\n",
    "    final_dataset = dataset.map(negative_combiner, num_proc=8)\n",
    "    return final_dataset\n",
    "\n",
    "final_dataset = negative_combiner_wrapper(long_dataset, language_title_dict, language_category_article_mapping, df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
