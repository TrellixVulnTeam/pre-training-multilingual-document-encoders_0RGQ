{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84859fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from itertools import product, chain\n",
    "from collections import defaultdict\n",
    "\n",
    "import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "sys.path.insert(0, '/home/ogalolu/thesis/pre-training-multilingual-document-encoders/clef')\n",
    "from evaluate import  _get_rerank_dir\n",
    "from clef_dataloaders.clef_dataloader import load_clef_rerank, load_relevance_assessments, load_clef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84affa32",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825b5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlang = \"en\"\n",
    "dlang = \"en\"\n",
    "root_dir = \"/work/ogalolu/datasets\"\n",
    "year = \"2002\"\n",
    "num_negative = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8881b5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number total documents: 169477\n"
     ]
    }
   ],
   "source": [
    "doc_ids, documents, query_ids, queries, relass = load_clef(qlang, dlang, year)\n",
    "print(\"The number total documents:\", len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d1a35",
   "metadata": {},
   "source": [
    "# Initial Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fab0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no relevance assesment for the following queries: {96, 132, 101, 110, 117, 118, 93, 127}\n"
     ]
    }
   ],
   "source": [
    "s1 = set(relass.keys())\n",
    "s2 = set(query_ids)\n",
    "print(\"There are no relevance assesment for the following queries:\", s2 - s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e871d6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available query-document pairs: 821\n"
     ]
    }
   ],
   "source": [
    "ids = list(chain.from_iterable(list(relass.values())))\n",
    "print(\"Number of available query-document pairs:\", len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d744d",
   "metadata": {},
   "source": [
    "# Obtain Training Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6675da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_negative(d_ind_list: list, num_negative: int) -> tuple:    \n",
    "    \"\"\" Find negative examples by excluding the given list of document indices.\"\"\"\n",
    "    all_set = set(range(len(documents)))\n",
    "    # To ensure that relevant documents won't appear in the set of negative examples\n",
    "    available_set = all_set - set(d_ind_list)\n",
    "    neg_ind_list = random.choices(tuple(available_set), k=num_negative)  \n",
    "    assert not any(x in neg_ind_list for x in d_ind_list)\n",
    "    negative_tuple = [documents[idx] for idx in neg_ind_list]\n",
    "    \n",
    "    return negative_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea79298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                     | 33/42 [00:08<00:02,  3.50it/s]"
     ]
    }
   ],
   "source": [
    "instance_list = list()\n",
    "for q_ind, d_ind in tqdm.tqdm(relass.items()):\n",
    "    temp_query = [queries[query_ids.index(q_ind)]]\n",
    "    temp_documents = [documents[doc_ids.index(idx)] for idx in d_ind]\n",
    "    temp_list = list(product(temp_query, temp_documents))  # list of tuples\n",
    "    \n",
    "    # if negative examples to be added, then for each training instance that has the same query, create a \n",
    "    # different set of negative examples, the number of negative examples is set at the beginning\n",
    "    \n",
    "    if num_negative is not None:\n",
    "        d_ind_list = [doc_ids.index(idx) for idx in d_ind]  \n",
    "        for q in temp_list:\n",
    "            temp_negatives = find_negative(d_ind_list, num_negative)\n",
    "            temp_tuple = (*q, *temp_negatives)\n",
    "            instance_list.append(temp_tuple)\n",
    "    else:\n",
    "        instance_list.extend(temp_list)\n",
    "\n",
    "assert len(instance_list) == len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_dic = defaultdict(list)\n",
    "for q, d, *negatives in instance_list:\n",
    "    # For the naming convengtion, \"article\" is used, whereas article_1 and article_2 are reserved for query and document\n",
    "    instance_dic[\"article_1\"].append(q)\n",
    "    instance_dic[\"article_2\"].append(d)\n",
    "    \n",
    "    # If negatives to be added    \n",
    "    if num_negative is not None:\n",
    "        for idx, neg in enumerate(negatives, 3):\n",
    "            instance_dic[f\"article_{idx}\"].append(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea53cf0",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebb4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(instance_dic)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "86fe92b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article_1', 'article_2', 'article_3', 'article_4', 'article_5', 'article_6', 'article_7', 'article_8', 'article_9', 'article_10'],\n",
      "        num_rows: 738\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article_1', 'article_2', 'article_3', 'article_4', 'article_5', 'article_6', 'article_7', 'article_8', 'article_9', 'article_10'],\n",
      "        num_rows: 83\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "d940404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(root_dir, f\"clef_{year}_{num_negative}\")\n",
    "dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9065e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
